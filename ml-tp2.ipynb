{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":631737,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":476142,"modelId":492061}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Baseline with Logistic Regression","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. 导入必要的库\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import log_loss, classification_report, confusion_matrix\nimport string\n\n# 2. 加载数据\ntrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\ntest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\n\n# 3. 特征工程：提取统计特征\n\ndef create_features(df):\n    # 长度特征\n    df['prompt_length'] = df['prompt'].str.len()\n    df['response_a_length'] = df['response_a'].str.len()\n    df['response_b_length'] = df['response_b'].str.len()\n    # 单词数\n    df['prompt_word_count'] = df['prompt'].str.split().str.len()\n    df['response_a_word_count'] = df['response_a'].str.split().str.len()\n    df['response_b_word_count'] = df['response_b'].str.split().str.len()\n    # 标点数\n    df['prompt_punc_count'] = df['prompt'].str.count(f'[{string.punctuation}]')\n    df['response_a_punc_count'] = df['response_a'].str.count(f'[{string.punctuation}]')\n    df['response_b_punc_count'] = df['response_b'].str.count(f'[{string.punctuation}]')\n    # 差异特征\n    df['response_length_diff'] = df['response_a_length'] - df['response_b_length']\n    df['response_word_diff'] = df['response_a_word_count'] - df['response_b_word_count']\n    return df\n\ntrain = create_features(train)\ntest = create_features(test)\n\n# 4. Label编码（可选：对model名称，但test不会用到）\nle = LabelEncoder()\nmodel_cols = []\nfor col in ['model_a', 'model_b']:\n    train[f'{col}_enc'] = le.fit_transform(train[col])\n    model_cols += [f'{col}_enc']\n\n# 5. 构造标签\n#   winner_model_a=1→类别0，winner_model_b=1→类别1，winner_tie=1→类别2\ntrain['target'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values.argmax(axis=1)\n\n# 6. 选定全部数值特征\nfeature_cols = [\n    'prompt_length', 'response_a_length', 'response_b_length',\n    'prompt_word_count', 'response_a_word_count', 'response_b_word_count',\n    'prompt_punc_count', 'response_a_punc_count', 'response_b_punc_count',\n    'response_length_diff', 'response_word_diff'\n    # 若希望，也可添加model_a_enc/model_b_enc\n]\n\nX = train[feature_cols]\ny = train['target']\n\n# 7. 数据拆分 + 标准化\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\n\n# 8. 逻辑回归训练\nclf = LogisticRegression(max_iter=1000, random_state=42, multi_class='ovr')\nclf.fit(X_train_scaled, y_train)\n\n# 9. 验证集效果\nval_pred_proba = clf.predict_proba(X_val_scaled)\nval_pred = clf.predict(X_val_scaled)\nprint('Validation Log Loss:', log_loss(y_val, val_pred_proba))\nprint('Classification Report:\\n', classification_report(y_val, val_pred, digits=4))\n\n# 10. 生成test特征、标准化并预测\nX_test = test[feature_cols]\nX_test_scaled = scaler.transform(X_test)\ntest_pred_proba = clf.predict_proba(X_test_scaled)\n\n# 11. 生成Kaggle提交文件\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'winner_model_a': test_pred_proba[:,0],\n    'winner_model_b': test_pred_proba[:,1],\n    'winner_tie': test_pred_proba[:,2],\n})\nsubmission.to_csv('submission_baseline.csv', index=False)\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:41:02.203709Z","iopub.execute_input":"2025-11-06T09:41:02.204413Z","iopub.status.idle":"2025-11-06T09:41:14.304691Z","shell.execute_reply.started":"2025-11-06T09:41:02.204381Z","shell.execute_reply":"2025-11-06T09:41:14.303056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Step 2: Embedding-based model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\ntrain = pd.read_csv('/kaggle/input/llm-classification-finetuning/train.csv')\ntest = pd.read_csv('/kaggle/input/llm-classification-finetuning/test.csv')\n\n# 用本地模型路径加载（路径需和你 Add Input 名称一致）\nmodel = SentenceTransformer('/kaggle/input/minilm-l12-v2-local/other/default/1/minilm_l12_v2_local')\n\n# 拼接文本\ndef concat_text(df):\n    return (\n        df['prompt'].astype(str) + ' ' + df['response_a'].astype(str),\n        df['prompt'].astype(str) + ' ' + df['response_b'].astype(str)\n    )\ntrain_a, train_b = concat_text(train)\ntest_a, test_b = concat_text(test)\n\nemb_a = model.encode(train_a.tolist(), batch_size=32, show_progress_bar=True)\nemb_b = model.encode(train_b.tolist(), batch_size=32, show_progress_bar=True)\nX = np.hstack([emb_a, emb_b, emb_a - emb_b])\ny = train[['winner_model_a','winner_model_b','winner_tie']].values.argmax(axis=1)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nclf = LogisticRegression(max_iter=1000)\nclf.fit(X_train, y_train)\nprint('Val Log Loss:', log_loss(y_val, clf.predict_proba(X_val)))\n\nemb_a_test = model.encode(test_a.tolist(), batch_size=32, show_progress_bar=True)\nemb_b_test = model.encode(test_b.tolist(), batch_size=32, show_progress_bar=True)\nX_test = np.hstack([emb_a_test, emb_b_test, emb_a_test - emb_b_test])\nproba = clf.predict_proba(X_test)\n\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'winner_model_a': proba[:,0],\n    'winner_model_b': proba[:,1],\n    'winner_tie': proba[:,2]\n})\nsubmission.to_csv('submission_emb.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T11:05:09.086277Z","iopub.execute_input":"2025-11-06T11:05:09.087032Z","iopub.status.idle":"2025-11-06T11:10:15.798781Z","shell.execute_reply.started":"2025-11-06T11:05:09.087003Z","shell.execute_reply":"2025-11-06T11:10:15.798246Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe26c0c477b40c2a9311dc9958bc7c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c2a68cf1ae44d6898e909972522110"}},"metadata":{}},{"name":"stdout","text":"Val Log Loss: 1.0668766656893598\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73909475f581467c9df2b444432439b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce680172c7c4fa092cb9f647c72cd58"}},"metadata":{}}],"execution_count":5}]}